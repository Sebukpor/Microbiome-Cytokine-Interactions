{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9108c-86f1-4832-b2b5-9209e9f6c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Full Processing Pipeline Setup\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.notebook import tqdm\n",
    "from Bio import SeqIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "MAX_WORKERS = 4  \n",
    "BATCH_SIZE = 10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb6fc2f-d966-4283-b5a4-bdbf9d6ac705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Enhanced Processing Functions\n",
    "def process_single_file(mgb_file, source_dir, dest_dir):\n",
    "    \"\"\"Process one MGB file with full error handling\"\"\"\n",
    "    try:\n",
    "        base_name = os.path.splitext(mgb_file)[0]\n",
    "        input_path = os.path.join(source_dir, mgb_file)\n",
    "        temp_fastq = os.path.join(source_dir, f\"{base_name}.fastq\")\n",
    "        \n",
    "        # Docker command - using Windows path conversion\n",
    "        host_dir = source_dir.replace('\\\\', '/')\n",
    "        command = [\n",
    "            \"docker\", \"run\", \"--rm\",\n",
    "            \"--memory=8g\", \"--memory-swap=12g\",\n",
    "            \"-v\", f\"{source_dir}:/data\",\n",
    "            \"muefab/genie:latest\", \"run\",\n",
    "            \"-f\",\n",
    "            \"-i\", f\"/data/{mgb_file}\",\n",
    "            \"-o\", f\"/data/{base_name}.fastq\"\n",
    "        ]\n",
    "        \n",
    "        # Run processing\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            return (False, mgb_file, result.stderr)\n",
    "        \n",
    "        # Verify and move output\n",
    "        if os.path.exists(temp_fastq):\n",
    "            final_path = os.path.join(dest_dir, f\"{base_name}.fastq\")\n",
    "            shutil.move(temp_fastq, final_path)\n",
    "            return (True, mgb_file, None)\n",
    "        return (False, mgb_file, \"Output file not created\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        return (False, mgb_file, str(e))\n",
    "\n",
    "def process_all_files(source_dir, dest_dir, max_workers=MAX_WORKERS):\n",
    "    \"\"\"Process all files in directory with parallel execution\"\"\"\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    mgb_files = [f for f in os.listdir(source_dir) if f.endswith(\".mgb\")]\n",
    "    \n",
    "    # Process files in parallel with progress bar\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        results = {'success': 0, 'failed': 0, 'errors': []}\n",
    "        \n",
    "        # Submit all tasks\n",
    "        for mgb_file in mgb_files:\n",
    "            futures.append(executor.submit(\n",
    "                process_single_file, \n",
    "                mgb_file, \n",
    "                source_dir, \n",
    "                dest_dir\n",
    "            ))\n",
    "        \n",
    "        # Monitor progress\n",
    "        with tqdm(total=len(mgb_files), desc=\"Processing Files\") as pbar:\n",
    "            for future in futures:\n",
    "                success, filename, error = future.result()\n",
    "                if success:\n",
    "                    results['success'] += 1\n",
    "                else:\n",
    "                    results['failed'] += 1\n",
    "                    results['errors'].append((filename, error))\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # Periodic status update\n",
    "                if results['success'] % BATCH_SIZE == 0:\n",
    "                    pbar.set_postfix({\n",
    "                        'Success': results['success'],\n",
    "                        'Failed': results['failed']\n",
    "                    })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d051c868-9c97-493c-ad4e-8ea34f4973e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training files processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b210b8d41447c68685cc94eda02287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files:   0%|          | 0/2901 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting test files processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382ff4cdec5f4ee78c8deeedeb6501a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files:   0%|          | 0/1068 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Complete!\n",
      "Training Files - Success: 2901, Failed: 0\n",
      "Test Files - Success: 1068, Failed: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Main Execution\n",
    "train_dir = r\"C:\\Users\\divin\\.cache\\kagglehub\\datasets\\maestroalert\\trainfiles\\versions\\1\\TrainFiles\"\n",
    "test_dir = r\"C:\\Users\\divin\\.cache\\kagglehub\\datasets\\maestroalert\\testfiles\\versions\\1\\TestFiles\"\n",
    "output_train = \"processed_data/train\"\n",
    "output_test = \"processed_data/test\"\n",
    "\n",
    "# Process training files\n",
    "print(\"Starting training files processing...\")\n",
    "train_results = process_all_files(train_dir, output_train)\n",
    "\n",
    "# Process test files\n",
    "print(\"\\nStarting test files processing...\")\n",
    "test_results = process_all_files(test_dir, output_test)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nProcessing Complete!\")\n",
    "print(f\"Training Files - Success: {train_results['success']}, Failed: {train_results['failed']}\")\n",
    "print(f\"Test Files - Success: {test_results['success']}, Failed: {test_results['failed']}\")\n",
    "\n",
    "# Save error log if any failures\n",
    "if train_results['failed'] > 0 or test_results['failed'] > 0:\n",
    "    with open(\"processing_errors.log\", \"w\") as f:\n",
    "        f.write(\"Training File Errors:\\n\")\n",
    "        for error in train_results['errors']:\n",
    "            f.write(f\"{error[0]}: {error[1]}\\n\")\n",
    "        f.write(\"\\nTest File Errors:\\n\")\n",
    "        for error in test_results['errors']:\n",
    "            f.write(f\"{error[0]}: {error[1]}\\n\")\n",
    "    print(\"Error log saved to processing_errors.log\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpegg_env",
   "language": "python",
   "name": "mpegg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
