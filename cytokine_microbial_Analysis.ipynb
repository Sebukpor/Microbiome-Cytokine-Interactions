{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmM1AkTO15xZXWVkZ+0lRD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sebukpor/Microbiome-Cytokine-Interactions/blob/main/cytokine_microbial_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-bio shap umap-learn --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyToFydGL4_n",
        "outputId": "08b88041-eaa2-47bd-8f92-eb6dd3a0130a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Comprehensive analysis pipeline for microbiome-cytokine datasets, focusing on multiple sample types: stool, gut, mouth, nasal.\n",
        "Includes diversity calculations, PERMANOVA, correlation analysis, differential abundance,\n",
        "machine learning, and network analysis.\n",
        "\"\"\"\n",
        "import os\n",
        "os.environ[\"SCIPY_ARRAY_API\"] = \"1\" # Enable SciPy array API for SMOTE compatibility\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import spearmanr, mannwhitneyu\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.manifold import TSNE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import networkx as nx\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from skbio.stats.distance import permanova, permdisp\n",
        "from skbio import DistanceMatrix\n",
        "from skbio.stats.ordination import pcoa\n",
        "from skbio.stats.composition import clr, multi_replace\n",
        "import warnings\n",
        "from datetime import datetime, timezone\n",
        "import json\n",
        "warnings.filterwarnings('ignore') # Suppress warnings for cleaner output\n",
        "# ----------------------- CONFIG -----------------------\n",
        "DATA_PATH = '/content/merged well cytokine-microbiome.csv'\n",
        "ID_COL = 'SampleID'\n",
        "OUTPUT_DIR = '/content/analysis_outputs'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ],
      "metadata": {
        "id": "IzNVhZgSo1_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZjsOraCLTUG",
        "outputId": "a099d53c-1926-45bb-8341-06eda2f56a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-05T11:44:41.405640+00:00] Loading data...\n",
            "[2025-10-05T11:44:41.513672+00:00] Duplicate SampleIDs found. Dropping duplicate rows, keeping first occurrence.\n",
            "[2025-10-05T11:44:41.514071+00:00] Data shape: (670, 308)\n",
            "[2025-10-05T11:44:41.516942+00:00] Detected microbe columns: 234; cytokines: 66; metadata: 5\n",
            "[2025-10-05T11:44:41.592107+00:00] Performing relative abundance and CLR transforms (with multi_replace) on full dataset.\n",
            "[2025-10-05T11:44:41.613910+00:00] Detected sample types: ['Stool' 'Mouth' 'Nasal' 'Skin']\n",
            "[2025-10-05T11:44:41.619789+00:00] Processing sample type: Stool\n",
            "[2025-10-05T11:44:41.623994+00:00] Computing alpha diversity for Stool...\n",
            "[2025-10-05T11:44:41.815962+00:00] Visualizing Shannon diversity by health status for Stool...\n",
            "[2025-10-05T11:44:42.170745+00:00] Visualizing class distribution for Stool...\n",
            "[2025-10-05T11:44:42.420453+00:00] Distance metric: aitchison for Stool\n",
            "[2025-10-05T11:44:42.420559+00:00] Computing distance matrix for Stool...\n",
            "[2025-10-05T11:44:42.426260+00:00] Using group_col for PERMANOVA: CL4 for Stool\n",
            "[2025-10-05T11:44:42.426319+00:00] Running PERMANOVA for Stool...\n",
            "[2025-10-05T11:44:42.484728+00:00] PERMANOVA complete for Stool. Result saved.\n",
            "[2025-10-05T11:44:42.485204+00:00] Running PERMDISP for Stool...\n",
            "[2025-10-05T11:45:18.284062+00:00] PERMDISP results saved for Stool.\n",
            "[2025-10-05T11:45:18.284215+00:00] Performing correlation analysis for Stool...\n",
            "[2025-10-05T11:45:18.365339+00:00] Keeping 12 taxa (prevalence >= 0.01) out of 234 for Stool\n",
            "[2025-10-05T11:45:20.671724+00:00] Significant correlations saved for Stool.\n",
            "[2025-10-05T11:45:20.671876+00:00] Generating correlation heatmap for Stool...\n",
            "[2025-10-05T11:45:20.958703+00:00] Performing differential abundance analysis for Stool...\n",
            "[2025-10-05T11:45:20.980035+00:00] Differential abundance results saved for Stool.\n",
            "[2025-10-05T11:45:20.980084+00:00] Training Random Forest classifier for Stool...\n",
            "[2025-10-05T11:45:20.984919+00:00] Classes after filtering (minimum 5 samples) for Stool: ['Healthy', 'Imz', 'Fiber', 'Infection', 'Infection_L']\n",
            "[2025-10-05T11:46:46.775471+00:00] Best Random Forest Parameters for Stool: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "[2025-10-05T11:46:46.792722+00:00] Random Forest Accuracy for Stool: 0.904\n",
            "[2025-10-05T11:46:46.816344+00:00] Feature importances saved for Stool.\n",
            "[2025-10-05T11:46:47.216916+00:00] Performing PCA and t-SNE for visualization in Stool...\n",
            "[2025-10-05T11:46:49.062263+00:00] Building microbe-cytokine correlation network for Stool...\n",
            "[2025-10-05T11:46:49.515092+00:00] Correlation network saved for Stool.\n",
            "[2025-10-05T11:46:49.515211+00:00] Performing temporal analysis for Stool...\n",
            "[2025-10-05T11:46:50.913384+00:00] Processing sample type: Mouth\n",
            "[2025-10-05T11:46:50.940795+00:00] Computing alpha diversity for Mouth...\n",
            "[2025-10-05T11:46:51.678152+00:00] Visualizing Shannon diversity by health status for Mouth...\n",
            "[2025-10-05T11:46:51.980272+00:00] Visualizing class distribution for Mouth...\n",
            "[2025-10-05T11:46:52.161507+00:00] Distance metric: aitchison for Mouth\n",
            "[2025-10-05T11:46:52.161557+00:00] Computing distance matrix for Mouth...\n",
            "[2025-10-05T11:46:52.164192+00:00] Using group_col for PERMANOVA: CL4 for Mouth\n",
            "[2025-10-05T11:46:52.164237+00:00] Running PERMANOVA for Mouth...\n",
            "[2025-10-05T11:46:52.212664+00:00] PERMANOVA complete for Mouth. Result saved.\n",
            "[2025-10-05T11:46:52.213419+00:00] Running PERMDISP for Mouth...\n",
            "[2025-10-05T11:47:06.666908+00:00] PERMDISP results saved for Mouth.\n",
            "[2025-10-05T11:47:06.667009+00:00] Performing correlation analysis for Mouth...\n",
            "[2025-10-05T11:47:06.681360+00:00] Keeping 14 taxa (prevalence >= 0.01) out of 234 for Mouth\n",
            "[2025-10-05T11:47:07.552630+00:00] Significant correlations saved for Mouth.\n",
            "[2025-10-05T11:47:07.552742+00:00] Performing differential abundance analysis for Mouth...\n",
            "[2025-10-05T11:47:07.579529+00:00] Differential abundance results saved for Mouth.\n",
            "[2025-10-05T11:47:07.579579+00:00] Training Random Forest classifier for Mouth...\n",
            "[2025-10-05T11:47:07.583735+00:00] Classes after filtering (minimum 5 samples) for Mouth: ['Healthy', 'Infection', 'Infection_L', 'Imz', 'Imz_L', 'Weight-loss']\n",
            "[2025-10-05T11:48:31.972679+00:00] Best Random Forest Parameters for Mouth: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "[2025-10-05T11:48:31.982711+00:00] Random Forest Accuracy for Mouth: 0.981\n",
            "[2025-10-05T11:48:32.001848+00:00] Feature importances saved for Mouth.\n",
            "[2025-10-05T11:48:32.290811+00:00] Performing PCA and t-SNE for visualization in Mouth...\n",
            "[2025-10-05T11:48:33.459374+00:00] Building microbe-cytokine correlation network for Mouth...\n",
            "[2025-10-05T11:48:33.757264+00:00] Correlation network saved for Mouth.\n",
            "[2025-10-05T11:48:33.757372+00:00] Performing temporal analysis for Mouth...\n",
            "[2025-10-05T11:48:34.349460+00:00] Processing sample type: Nasal\n",
            "[2025-10-05T11:48:34.353176+00:00] Computing alpha diversity for Nasal...\n",
            "[2025-10-05T11:48:34.512215+00:00] Visualizing Shannon diversity by health status for Nasal...\n",
            "[2025-10-05T11:48:34.756803+00:00] Visualizing class distribution for Nasal...\n",
            "[2025-10-05T11:48:34.925724+00:00] Distance metric: aitchison for Nasal\n",
            "[2025-10-05T11:48:34.925768+00:00] Computing distance matrix for Nasal...\n",
            "[2025-10-05T11:48:34.930061+00:00] Using group_col for PERMANOVA: CL4 for Nasal\n",
            "[2025-10-05T11:48:34.930113+00:00] Running PERMANOVA for Nasal...\n",
            "[2025-10-05T11:48:34.985408+00:00] PERMANOVA complete for Nasal. Result saved.\n",
            "[2025-10-05T11:48:34.986751+00:00] Running PERMDISP for Nasal...\n",
            "[2025-10-05T11:48:47.836725+00:00] PERMDISP results saved for Nasal.\n",
            "[2025-10-05T11:48:47.836827+00:00] Performing correlation analysis for Nasal...\n",
            "[2025-10-05T11:48:47.849881+00:00] Keeping 13 taxa (prevalence >= 0.01) out of 234 for Nasal\n",
            "[2025-10-05T11:48:48.662140+00:00] Significant correlations saved for Nasal.\n",
            "[2025-10-05T11:48:48.662267+00:00] Performing differential abundance analysis for Nasal...\n",
            "[2025-10-05T11:48:48.684504+00:00] Differential abundance results saved for Nasal.\n",
            "[2025-10-05T11:48:48.684561+00:00] Training Random Forest classifier for Nasal...\n",
            "[2025-10-05T11:48:48.688970+00:00] Classes after filtering (minimum 5 samples) for Nasal: ['Healthy', 'Imz', 'Infection', 'Infection_L', 'Imz_L']\n",
            "[2025-10-05T11:50:15.308878+00:00] Best Random Forest Parameters for Nasal: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "[2025-10-05T11:50:15.349911+00:00] Random Forest Accuracy for Nasal: 0.919\n",
            "[2025-10-05T11:50:15.398930+00:00] Feature importances saved for Nasal.\n",
            "[2025-10-05T11:50:15.692533+00:00] Performing PCA and t-SNE for visualization in Nasal...\n",
            "[2025-10-05T11:50:16.990177+00:00] Building microbe-cytokine correlation network for Nasal...\n",
            "[2025-10-05T11:50:17.279687+00:00] Correlation network saved for Nasal.\n",
            "[2025-10-05T11:50:17.279787+00:00] Performing temporal analysis for Nasal...\n",
            "[2025-10-05T11:50:17.668923+00:00] Processing sample type: Skin\n",
            "[2025-10-05T11:50:17.672663+00:00] Computing alpha diversity for Skin...\n",
            "[2025-10-05T11:50:17.799383+00:00] Visualizing Shannon diversity by health status for Skin...\n",
            "[2025-10-05T11:50:18.047007+00:00] Visualizing class distribution for Skin...\n",
            "[2025-10-05T11:50:18.223928+00:00] Distance metric: aitchison for Skin\n",
            "[2025-10-05T11:50:18.223973+00:00] Computing distance matrix for Skin...\n",
            "[2025-10-05T11:50:18.226739+00:00] Using group_col for PERMANOVA: CL4 for Skin\n",
            "[2025-10-05T11:50:18.226784+00:00] Running PERMANOVA for Skin...\n",
            "[2025-10-05T11:50:18.275801+00:00] PERMANOVA complete for Skin. Result saved.\n",
            "[2025-10-05T11:50:18.276270+00:00] Running PERMDISP for Skin...\n",
            "[2025-10-05T11:50:30.819027+00:00] PERMDISP results saved for Skin.\n",
            "[2025-10-05T11:50:30.819128+00:00] Performing correlation analysis for Skin...\n",
            "[2025-10-05T11:50:30.832575+00:00] Keeping 10 taxa (prevalence >= 0.01) out of 234 for Skin\n",
            "[2025-10-05T11:50:31.453854+00:00] Significant correlations saved for Skin.\n",
            "[2025-10-05T11:50:31.453966+00:00] Generating correlation heatmap for Skin...\n",
            "[2025-10-05T11:50:31.669555+00:00] Performing differential abundance analysis for Skin...\n",
            "[2025-10-05T11:50:31.695888+00:00] Differential abundance results saved for Skin.\n",
            "[2025-10-05T11:50:31.695942+00:00] Training Random Forest classifier for Skin...\n",
            "[2025-10-05T11:50:31.700457+00:00] Classes after filtering (minimum 5 samples) for Skin: ['Healthy', 'Imz', 'Infection', 'Infection_L', 'Imz_L', 'Fiber']\n",
            "[2025-10-05T11:51:46.384079+00:00] Best Random Forest Parameters for Skin: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "[2025-10-05T11:51:46.401215+00:00] Random Forest Accuracy for Skin: 0.920\n",
            "[2025-10-05T11:51:46.426288+00:00] Feature importances saved for Skin.\n",
            "[2025-10-05T11:51:46.675816+00:00] Performing PCA and t-SNE for visualization in Skin...\n",
            "[2025-10-05T11:51:48.092831+00:00] Building microbe-cytokine correlation network for Skin...\n",
            "[2025-10-05T11:51:48.519846+00:00] Correlation network saved for Skin.\n",
            "[2025-10-05T11:51:48.520213+00:00] Performing temporal analysis for Skin...\n",
            "[2025-10-05T11:51:49.316682+00:00] Performing combined analyses across all sample types...\n",
            "[2025-10-05T11:51:55.501905+00:00] Running combined PERMANOVA with SampleType as grouping...\n",
            "[2025-10-05T11:51:55.961599+00:00] Writing summary report...\n",
            "[2025-10-05T11:51:55.962883+00:00] Summary report saved.\n",
            "[2025-10-05T11:51:55.962954+00:00] Analysis complete. Results saved in OUTPUT_DIR.\n"
          ]
        }
      ],
      "source": [
        "# Logging function\n",
        "def log(msg):\n",
        "    print(f\"[{datetime.now(timezone.utc).isoformat()}] {msg}\")\n",
        "\n",
        "# Load the dataset\n",
        "log(\"Loading data...\")\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Drop duplicates based on SampleID\n",
        "df = df.drop_duplicates(subset=ID_COL, keep='first')\n",
        "log(f\"Duplicate SampleIDs found. Dropping duplicate rows, keeping first occurrence.\")\n",
        "log(f\"Data shape: {df.shape}\")\n",
        "\n",
        "# Exclude summary rows (e.g., geomean)\n",
        "df = df[df['Plate'] != 'geomean']\n",
        "\n",
        "# Identify columns\n",
        "columns = df.columns.tolist()\n",
        "microbe_start = columns.index('Abyssalbus')\n",
        "microbe_end = columns.index('Plate')\n",
        "microbe_cols = columns[microbe_start:microbe_end]\n",
        "cytokine_start = columns.index('IL17F')\n",
        "cytokine_end = columns.index('CollectionDate')\n",
        "cytokine_cols = columns[cytokine_start:cytokine_end]\n",
        "metadata_cols = columns[cytokine_end:]\n",
        "log(f\"Detected microbe columns: {len(microbe_cols)}; cytokines: {len(cytokine_cols)}; metadata: {len(metadata_cols)}\")\n",
        "\n",
        "# Convert to numeric and handle NaNs\n",
        "df[microbe_cols] = df[microbe_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "df[cytokine_cols] = df[cytokine_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "\n",
        "# Set index\n",
        "df = df.set_index(ID_COL)\n",
        "\n",
        "# Compute relative abundances and CLR transform for all\n",
        "log(\"Performing relative abundance and CLR transforms (with multi_replace) on full dataset.\")\n",
        "microbe_totals = df[microbe_cols].sum(axis=1)\n",
        "rel_microbe_df = df[microbe_cols].div(microbe_totals, axis=0).replace([np.inf, -np.inf], 0).fillna(0)\n",
        "clr_microbe_df = pd.DataFrame(\n",
        "    clr(multi_replace(rel_microbe_df.values)),\n",
        "    index=rel_microbe_df.index,\n",
        "    columns=rel_microbe_df.columns\n",
        ")\n",
        "\n",
        "# Get unique sample types\n",
        "sample_types = df['SampleType'].unique()\n",
        "log(f\"Detected sample types: {sample_types}\")\n",
        "\n",
        "# Alpha diversity functions\n",
        "def shannon_diversity(row):\n",
        "    p = row[row > 0]\n",
        "    if p.empty or p.sum() == 0:\n",
        "        return 0\n",
        "    p = p / p.sum()\n",
        "    return -np.sum(p * np.log(p))\n",
        "def simpson_diversity(row):\n",
        "    p = row[row > 0]\n",
        "    if p.empty or p.sum() == 0:\n",
        "        return 0\n",
        "    p = p / p.sum()\n",
        "    return 1 - np.sum(p**2)\n",
        "\n",
        "# Loop over each sample type\n",
        "for sample_type in sample_types:\n",
        "    log(f\"Processing sample type: {sample_type}\")\n",
        "    type_df = df[df['SampleType'] == sample_type].copy()\n",
        "    if type_df.empty:\n",
        "        log(f\"No samples for {sample_type}. Skipping.\")\n",
        "        continue\n",
        "    rel_type_microbe = rel_microbe_df.loc[type_df.index].copy()\n",
        "    clr_type_microbe = clr_microbe_df.loc[type_df.index].copy()\n",
        "\n",
        "    # Alpha diversity calculations\n",
        "    log(f\"Computing alpha diversity for {sample_type}...\")\n",
        "    diversity_df = pd.DataFrame({\n",
        "        'Shannon_Diversity': rel_type_microbe.apply(shannon_diversity, axis=1),\n",
        "        'Simpson_Diversity': rel_type_microbe.apply(simpson_diversity, axis=1)\n",
        "    }, index=type_df.index)\n",
        "    type_df = pd.concat([type_df, diversity_df], axis=1)\n",
        "\n",
        "    # Create type-specific output dir\n",
        "    type_output_dir = os.path.join(OUTPUT_DIR, sample_type.lower())\n",
        "    os.makedirs(type_output_dir, exist_ok=True)\n",
        "\n",
        "    # Visualize diversity by health status\n",
        "    log(f\"Visualizing Shannon diversity by health status for {sample_type}...\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(x='CL4', y='Shannon_Diversity', data=type_df)\n",
        "    plt.title(f'Shannon Diversity by Health Status ({sample_type} Samples)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.savefig(os.path.join(type_output_dir, 'shannon_by_status.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Visualize class distribution\n",
        "    log(f\"Visualizing class distribution for {sample_type}...\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    class_counts = type_df['CL4'].value_counts()\n",
        "    class_counts.plot(kind='bar')\n",
        "    plt.title(f'Class Distribution in CL4 ({sample_type} Samples)')\n",
        "    plt.xlabel('Health Status')\n",
        "    plt.ylabel('Sample Count')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.savefig(os.path.join(type_output_dir, 'class_distribution.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # PERMANOVA and PERMDISP with Aitchison distance\n",
        "    log(f\"Distance metric: aitchison for {sample_type}\")\n",
        "    log(f\"Computing distance matrix for {sample_type}...\")\n",
        "    dist_array = pdist(clr_type_microbe.values, metric='euclidean')\n",
        "    dm = DistanceMatrix(squareform(dist_array), ids=clr_type_microbe.index.tolist())\n",
        "    log(f\"Using group_col for PERMANOVA: CL4 for {sample_type}\")\n",
        "    log(f\"Running PERMANOVA for {sample_type}...\")\n",
        "    common_ids = [id_ for id_ in dm.ids if id_ in type_df.index]\n",
        "    if not common_ids:\n",
        "        log(f\"No common IDs for {sample_type}. Skipping PERMANOVA and PERMDISP.\")\n",
        "        permanova_result = {'test statistic': np.nan, 'p-value': np.nan}\n",
        "        permdisp_result = {'test statistic': np.nan, 'p-value': np.nan}\n",
        "    else:\n",
        "        dm_filtered = dm.filter(common_ids)\n",
        "        grouping = type_df.loc[common_ids, 'CL4'].astype(str)\n",
        "        if len(grouping) < 2 or len(grouping.unique()) < 2:\n",
        "            log(f\"Insufficient samples or groups for PERMANOVA in {sample_type}. Skipping.\")\n",
        "            permanova_result = {'test statistic': np.nan, 'p-value': np.nan}\n",
        "        else:\n",
        "            permanova_result = permanova(dm_filtered, grouping=grouping, permutations=999)\n",
        "        log(f\"PERMANOVA complete for {sample_type}. Result saved.\")\n",
        "        with open(os.path.join(type_output_dir, 'permanova_result.json'), 'w') as f:\n",
        "            json.dump({\n",
        "                'test_statistic': float(permanova_result['test statistic']),\n",
        "                'p_value': float(permanova_result['p-value']),\n",
        "                'permutations': 999\n",
        "            }, f, indent=2)\n",
        "        log(f\"Running PERMDISP for {sample_type}...\")\n",
        "        pcoa_result = pcoa(dm_filtered)\n",
        "        coords = pcoa_result.samples\n",
        "        coords['CL4'] = type_df.loc[coords.index, 'CL4']  # Ensure index alignment\n",
        "        centroid_dfs = []\n",
        "        for g, sub in coords.groupby('CL4'):\n",
        "            if sub.shape[0] < 2:  # Skip groups with insufficient samples\n",
        "                continue\n",
        "            center = sub.iloc[:, :-1].mean(axis=0).values\n",
        "            arr = sub.iloc[:, :-1].values\n",
        "            dists = np.linalg.norm(arr - center[np.newaxis, :], axis=1)\n",
        "            centroid_dfs.append(pd.DataFrame({'group': [g] * len(dists), 'distance': dists}))\n",
        "        if not centroid_dfs:\n",
        "            log(f\"No valid groups for PERMDISP in {sample_type}. Skipping.\")\n",
        "            centroid_df = pd.DataFrame(columns=['group', 'distance'])\n",
        "            permdisp_result = {'test statistic': np.nan, 'p-value': np.nan}\n",
        "        else:\n",
        "            centroid_df = pd.concat(centroid_dfs, ignore_index=True)\n",
        "            if len(grouping.unique()) < 2:\n",
        "                log(f\"Insufficient groups for PERMDISP in {sample_type}. Skipping.\")\n",
        "                permdisp_result = {'test statistic': np.nan, 'p-value': np.nan}\n",
        "            else:\n",
        "                permdisp_result = permdisp(dm_filtered, grouping=grouping, permutations=999)\n",
        "        centroid_df.to_csv(os.path.join(type_output_dir, 'permdisp_distances.csv'), index=False)\n",
        "        with open(os.path.join(type_output_dir, 'permdisp_result.json'), 'w') as f:\n",
        "            json.dump({\n",
        "                'test_statistic': float(permdisp_result['test statistic']),\n",
        "                'p_value': float(permdisp_result['p-value']),\n",
        "                'permutations': 999\n",
        "            }, f, indent=2)\n",
        "        log(f\"PERMDISP results saved for {sample_type}.\")\n",
        "\n",
        "    # Correlation analysis\n",
        "    log(f\"Performing correlation analysis for {sample_type}...\")\n",
        "    abundant_microbes = [col for col in microbe_cols if rel_type_microbe[col].mean() > 0.01]\n",
        "    log(f\"Keeping {len(abundant_microbes)} taxa (prevalence >= 0.01) out of {len(microbe_cols)} for {sample_type}\")\n",
        "    corrs = []\n",
        "    pvals = []\n",
        "    pairs = []\n",
        "    for m in abundant_microbes:\n",
        "        for c in cytokine_cols:\n",
        "            r, p = spearmanr(clr_type_microbe[m], type_df[c], nan_policy='omit')\n",
        "            pairs.append((m, c))\n",
        "            corrs.append(r)\n",
        "            pvals.append(p)\n",
        "    _, corrected_pvals, _, _ = multipletests(pvals, method='fdr_bh')\n",
        "    corr_df = pd.DataFrame({\n",
        "        'Microbe': [p[0] for p in pairs],\n",
        "        'Cytokine': [p[1] for p in pairs],\n",
        "        'Correlation': corrs,\n",
        "        'P-value': pvals,\n",
        "        'Corrected_P-value': corrected_pvals\n",
        "    })\n",
        "    significant_corrs = corr_df[corr_df['Corrected_P-value'] < 0.05]\n",
        "    significant_corrs.to_csv(os.path.join(type_output_dir, 'significant_correlations.csv'), index=False)\n",
        "    log(f\"Significant correlations saved for {sample_type}.\")\n",
        "\n",
        "    # Heatmap of significant correlations\n",
        "    if not significant_corrs.empty:\n",
        "        log(f\"Generating correlation heatmap for {sample_type}...\")\n",
        "        pivot_corr = significant_corrs.pivot(index='Microbe', columns='Cytokine', values='Correlation').fillna(0)\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(pivot_corr, cmap='coolwarm', annot=True, fmt='.2f')\n",
        "        plt.title(f'Significant Spearman Correlations between Microbes and Cytokines ({sample_type})')\n",
        "        plt.savefig(os.path.join(type_output_dir, 'corr_heatmap.png'))\n",
        "        plt.close()\n",
        "\n",
        "    # Differential abundance analysis (Healthy vs Infection)\n",
        "    log(f\"Performing differential abundance analysis for {sample_type}...\")\n",
        "    healthy_type = type_df[type_df['CL4'] == 'Healthy'].copy()\n",
        "    infection_type = type_df[type_df['CL4'] == 'Infection'].copy()\n",
        "    diff_abund = []\n",
        "    diff_pvals = []\n",
        "    valid_microbes = []\n",
        "    for m in abundant_microbes:\n",
        "        if healthy_type[m].sum() > 0 or infection_type[m].sum() > 0:\n",
        "            stat, p = mannwhitneyu(healthy_type[m], infection_type[m], alternative='two-sided')\n",
        "            diff_abund.append(healthy_type[m].mean() - infection_type[m].mean())\n",
        "            diff_pvals.append(p)\n",
        "            valid_microbes.append(m)\n",
        "    _, diff_corrected_p, _, _ = multipletests(diff_pvals, method='fdr_bh')\n",
        "    diff_df = pd.DataFrame({\n",
        "        'Microbe': valid_microbes,\n",
        "        'Mean_Diff': diff_abund,\n",
        "        'P-value': diff_pvals,\n",
        "        'Corrected_P-value': diff_corrected_p\n",
        "    })\n",
        "    significant_diff = diff_df[diff_df['Corrected_P-value'] < 0.05].sort_values('Corrected_P-value')\n",
        "    significant_diff.to_csv(os.path.join(type_output_dir, 'differential_abundance.csv'), index=False)\n",
        "    log(f\"Differential abundance results saved for {sample_type}.\")\n",
        "\n",
        "    # Visualize top differentially abundant microbes\n",
        "    if not significant_diff.empty:\n",
        "        log(f\"Visualizing top differentially abundant microbes for {sample_type}...\")\n",
        "        top_diff = significant_diff.head(10)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x='Mean_Diff', y='Microbe', data=top_diff)\n",
        "        plt.title(f'Top Differentially Abundant Microbes (Healthy vs Infection) - {sample_type}')\n",
        "        plt.xlabel('Mean Difference (Healthy - Infection)')\n",
        "        plt.savefig(os.path.join(type_output_dir, 'diff_abundance.png'))\n",
        "        plt.close()\n",
        "\n",
        "    # Machine Learning: Predict health status\n",
        "    log(f\"Training Random Forest classifier for {sample_type}...\")\n",
        "    features = pd.concat([clr_type_microbe, type_df[cytokine_cols]], axis=1)\n",
        "    target = type_df['CL4']\n",
        "\n",
        "    # Filter classes with <5 samples\n",
        "    class_counts = target.value_counts()\n",
        "    valid_classes = class_counts[class_counts >= 5].index\n",
        "    filtered_type_df = type_df[type_df['CL4'].isin(valid_classes)].copy()\n",
        "    filtered_features = features.loc[filtered_type_df.index].copy()\n",
        "    log(f\"Classes after filtering (minimum 5 samples) for {sample_type}: {valid_classes.tolist()}\")\n",
        "\n",
        "    # Update features and target\n",
        "    features = filtered_features\n",
        "    target = filtered_type_df['CL4']\n",
        "    if len(target.unique()) < 2 or len(target) < 10:\n",
        "        log(f\"Insufficient classes or samples for ML in {sample_type}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Encode target\n",
        "    le = LabelEncoder()\n",
        "    target_enc = le.fit_transform(target)\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "    # Apply SMOTE with adjusted k_neighbors\n",
        "    min_k_neighbors = min(min(class_counts[valid_classes]), 5) - 1\n",
        "    min_k_neighbors = max(1, min_k_neighbors)  # Ensure at least 1 neighbor\n",
        "    smote = SMOTE(random_state=RANDOM_STATE, k_neighbors=min_k_neighbors)\n",
        "    X_resampled, y_resampled = smote.fit_resample(features_scaled, target_enc)\n",
        "\n",
        "    # Train-test split with stratification\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=RANDOM_STATE, stratify=y_resampled)\n",
        "\n",
        "    # Get unique classes in y_test\n",
        "    test_classes = np.unique(y_test)\n",
        "    test_class_names = le.inverse_transform(test_classes)\n",
        "\n",
        "    # Random Forest with hyperparameter tuning\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [10, 20, None],\n",
        "        'min_samples_split': [2, 5]\n",
        "    }\n",
        "    rf = RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced')\n",
        "    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_rf = grid_search.best_estimator_\n",
        "    log(f\"Best Random Forest Parameters for {sample_type}: {grid_search.best_params_}\")\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = best_rf.predict(X_test)\n",
        "    log(f\"Random Forest Accuracy for {sample_type}: {accuracy_score(y_test, y_pred):.3f}\")\n",
        "    with open(os.path.join(type_output_dir, 'rf_classification_report.txt'), 'w') as f:\n",
        "        f.write(classification_report(y_test, y_pred, target_names=test_class_names, zero_division=0))\n",
        "\n",
        "    # Feature importances\n",
        "    importances = pd.DataFrame({\n",
        "        'Feature': features.columns,\n",
        "        'Importance': best_rf.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False).head(20)\n",
        "    importances.to_csv(os.path.join(type_output_dir, 'feature_importances.csv'), index=False)\n",
        "    log(f\"Feature importances saved for {sample_type}.\")\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.barplot(x='Importance', y='Feature', data=importances)\n",
        "    plt.title(f'Top 20 Feature Importances for Predicting Health Status ({sample_type})')\n",
        "    plt.savefig(os.path.join(type_output_dir, 'feature_importances.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Dimensionality reduction for visualization\n",
        "    log(f\"Performing PCA and t-SNE for visualization in {sample_type}...\")\n",
        "    pca = PCA(n_components=2)\n",
        "    pca_features = pca.fit_transform(features_scaled)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    scatter = plt.scatter(pca_features[:, 0], pca_features[:, 1], c=target_enc, cmap='viridis')\n",
        "    plt.colorbar(scatter, ticks=range(len(le.classes_)), label='Status', format=lambda i, _: le.classes_[int(i)])\n",
        "    plt.title(f'PCA of Microbiome and Cytokine Data ({sample_type} Samples)')\n",
        "    plt.savefig(os.path.join(type_output_dir, 'pca_plot.png'))\n",
        "    plt.close()\n",
        "    tsne = TSNE(n_components=2, random_state=RANDOM_STATE)\n",
        "    tsne_features = tsne.fit_transform(features_scaled)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    scatter = plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=target_enc, cmap='viridis')\n",
        "    plt.colorbar(scatter, ticks=range(len(le.classes_)), label='Status', format=lambda i, _: le.classes_[int(i)])\n",
        "    plt.title(f't-SNE of Microbiome and Cytokine Data ({sample_type} Samples)')\n",
        "    plt.savefig(os.path.join(type_output_dir, 'tsne_plot.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Network analysis\n",
        "    log(f\"Building microbe-cytokine correlation network for {sample_type}...\")\n",
        "    G = nx.Graph()\n",
        "    G.add_nodes_from(abundant_microbes, type='microbe')\n",
        "    G.add_nodes_from(cytokine_cols, type='cytokine')\n",
        "    for idx, row in significant_corrs.iterrows():\n",
        "        if abs(row['Correlation']) > 0.3:\n",
        "            G.add_edge(row['Microbe'], row['Cytokine'], weight=row['Correlation'])\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    pos = nx.spring_layout(G)\n",
        "    node_colors = ['blue' if G.nodes[n]['type'] == 'microbe' else 'red' for n in G.nodes]\n",
        "    nx.draw(G, pos, with_labels=True, node_color=node_colors, edge_color='gray', node_size=500, font_size=8)\n",
        "    plt.title(f'Microbe-Cytokine Correlation Network (|r| > 0.3, FDR p < 0.05) - {sample_type}')\n",
        "    plt.savefig(os.path.join(type_output_dir, 'network.png'))\n",
        "    plt.close()\n",
        "    nx.write_gml(G, os.path.join(type_output_dir, 'correlation_network.gml'))\n",
        "    log(f\"Correlation network saved for {sample_type}.\")\n",
        "\n",
        "    # Temporal analysis\n",
        "    log(f\"Performing temporal analysis for {sample_type}...\")\n",
        "    type_df['CollectionDate'] = pd.to_datetime(type_df['CollectionDate'], errors='coerce')\n",
        "    time_analysis = type_df.groupby([type_df['CollectionDate'].dt.year, 'CL4'])[['Shannon_Diversity'] + cytokine_cols].mean().reset_index()\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.lineplot(data=time_analysis, x='CollectionDate', y='Shannon_Diversity', hue='CL4')\n",
        "    plt.title(f'Shannon Diversity Over Time by Health Status ({sample_type})')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.savefig(os.path.join(type_output_dir, 'temporal_diversity.png'))\n",
        "    plt.close()\n",
        "\n",
        "# Combined analyses across sample types\n",
        "log(\"Performing combined analyses across all sample types...\")\n",
        "# Combined t-SNE colored by SampleType and CL4\n",
        "features_all = pd.concat([clr_microbe_df, df[cytokine_cols]], axis=1)\n",
        "target_all = df['CL4']\n",
        "sample_type_all = df['SampleType']\n",
        "le_cl4 = LabelEncoder()\n",
        "target_enc_all = le_cl4.fit_transform(target_all)\n",
        "le_type = LabelEncoder()\n",
        "type_enc_all = le_type.fit_transform(sample_type_all)\n",
        "scaler_all = StandardScaler()\n",
        "features_scaled_all = scaler_all.fit_transform(features_all)\n",
        "tsne_all = TSNE(n_components=2, random_state=RANDOM_STATE)\n",
        "tsne_features_all = tsne_all.fit_transform(features_scaled_all)\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(tsne_features_all[:, 0], tsne_features_all[:, 1], c=type_enc_all, cmap='viridis')\n",
        "plt.colorbar(scatter, ticks=range(len(le_type.classes_)), label='SampleType', format=lambda i, _: le_type.classes_[int(i)])\n",
        "plt.title('t-SNE of Microbiome and Cytokine Data (All Samples, Colored by SampleType)')\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'combined_tsne_by_type.png'))\n",
        "plt.close()\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(tsne_features_all[:, 0], tsne_features_all[:, 1], c=target_enc_all, cmap='viridis')\n",
        "plt.colorbar(scatter, ticks=range(len(le_cl4.classes_)), label='Status', format=lambda i, _: le_cl4.classes_[int(i)])\n",
        "plt.title('t-SNE of Microbiome and Cytokine Data (All Samples, Colored by CL4)')\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'combined_tsne_by_cl4.png'))\n",
        "plt.close()\n",
        "\n",
        "# Combined PERMANOVA with SampleType as group\n",
        "log(\"Running combined PERMANOVA with SampleType as grouping...\")\n",
        "dist_array_all = pdist(clr_microbe_df.values, metric='euclidean')\n",
        "dm_all = DistanceMatrix(squareform(dist_array_all), ids=clr_microbe_df.index.tolist())\n",
        "common_ids_all = [id_ for id_ in dm_all.ids if id_ in df.index]\n",
        "dm_filtered_all = dm_all.filter(common_ids_all)\n",
        "grouping_all = df.loc[common_ids_all, 'SampleType'].astype(str)\n",
        "if len(grouping_all.unique()) >= 2:\n",
        "    permanova_all = permanova(dm_filtered_all, grouping=grouping_all, permutations=999)\n",
        "    with open(os.path.join(OUTPUT_DIR, 'combined_permanova_by_type.json'), 'w') as f:\n",
        "        json.dump({\n",
        "            'test_statistic': float(permanova_all['test statistic']),\n",
        "            'p_value': float(permanova_all['p-value']),\n",
        "            'permutations': 999\n",
        "        }, f, indent=2)\n",
        "\n",
        "# Summary report\n",
        "log(\"Writing summary report...\")\n",
        "report_lines = []\n",
        "report_lines.append(f\"# Analysis Summary\\nGenerated: {datetime.now(timezone.utc).isoformat()} UTC\\n\")\n",
        "report_lines.append(\"## Data Overview\")\n",
        "report_lines.append(f\"- Samples: {df.shape[0]}\")\n",
        "report_lines.append(f\"- Sample Types: {', '.join(sample_types)}\")\n",
        "report_lines.append(f\"- Microbe columns: {len(microbe_cols)}, Cytokines: {len(cytokine_cols)}, Metadata: {len(metadata_cols)}\")\n",
        "report_lines.append(\"\\n## Output Structure\")\n",
        "report_lines.append(\"- Site-specific outputs in subfolders: stool, gut, mouth, nasal\")\n",
        "report_lines.append(\"- Combined outputs in root OUTPUT_DIR\")\n",
        "report_lines.append(\"\\n## Key Combined Results\")\n",
        "if 'permanova_all' in locals():\n",
        "    report_lines.append(f\"- Combined PERMANOVA (by SampleType): Pseudo-F={permanova_all['test statistic']:.4f}, p={permanova_all['p-value']:.4f}\")\n",
        "report_text = \"\\n\".join(report_lines)\n",
        "with open(os.path.join(OUTPUT_DIR, 'summary_report.md'), 'w') as f:\n",
        "    f.write(report_text)\n",
        "log(\"Summary report saved.\")\n",
        "log(\"Analysis complete. Results saved in OUTPUT_DIR.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/analysis_outputs', 'zip', '/content/analysis_outputs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QH6FZzZOOog4",
        "outputId": "3c386246-8ec9-443f-cd88-552be8bb1902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/analysis_outputs.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}